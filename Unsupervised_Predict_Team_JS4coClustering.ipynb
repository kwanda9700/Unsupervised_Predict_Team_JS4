{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Challenge Description\n\n\nIn today’s technology driven world, recommender systems are socially and economically critical for ensuring that individuals can make appropriate choices surrounding the content they engage with on a daily basis. One application where this is especially true surrounds movie content recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n\nWith this context, EDSA is challenging you to construct a recommendation algorithm based on content or collaborative filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed based on their historical preferences.\n\nProviding an accurate and robust solution to this challenge has immense economic potential, with users of the system being exposed to content they would like to view or purchase - generating revenue and platform affinity.","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement","metadata":{}},{"cell_type":"markdown","source":"The evaluation metric for this competition is Root Mean Square Error. Root Mean Square Error  is commonly used in regression analysis and forecasting, and measures the standard deviation of the residuals arising between predicted and actual observed values for a modelling process. For our task of generating user movie ratings via recommendation algorithms, the the formula is given by:\n\nWhere \\\\( \\hat{R} \\\\) is the total number of recommendations generated for users and movies, with \\\\( r_{ui} \\\\) and \\\\( \\hat{r}_{ui} \\\\) being the true and predicted ratings for user \\\\( u \\\\) watching movie \\\\( i \\\\) respectively.\n\n### Submission Format\nFor every author in the dataset, submission files should contain two columns: Id and rating. 'Id' is a concatenation of the userID and movieID given in the test file using an '_' character. 'rating' is the predicted rating for a given user-movie pair","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nThe followig aims to get you up and running with the predict. Make a copy of the notebook and run all cells. We will also show you how to get your submission file from kaggle. ","metadata":{}},{"cell_type":"markdown","source":"## Installing packages\nPlease download all relevant packages in. There is no terminal so you will pip install everything.\n\nYou can find a list of recommended install from the Intro to Recommender sysytem notebook.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T18:12:21.352395Z","iopub.execute_input":"2021-07-15T18:12:21.352858Z","iopub.status.idle":"2021-07-15T18:12:21.368727Z","shell.execute_reply.started":"2021-07-15T18:12:21.352756Z","shell.execute_reply":"2021-07-15T18:12:21.367588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Installing packages\nPlease download all relevant packages in. There is no terminal so you will pip install everything.\n\nYou can find a list of recommended install from the Intro to Recommender sysytem notebook.","metadata":{}},{"cell_type":"code","source":"# Install packages here\n# Packages for data processing\nimport numpy as np\nimport pandas as pd\nimport datetime\nfrom sklearn import preprocessing\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport re\nfrom scipy.sparse import csr_matrix\nimport scipy as sp\n\n# importing the libraries\n\nimport math\nimport random\nimport json\nimport re\nfrom scipy.sparse.linalg import svds\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\n\n# Packages for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom wordcloud import WordCloud, STOPWORDS\n\n\n# Packages for modeling\nfrom surprise import NormalPredictor\nfrom surprise import Reader\nfrom surprise import Dataset\nfrom surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\nfrom surprise import BaselineOnly, SlopeOne, CoClustering\nfrom surprise.model_selection import cross_validate\nfrom surprise import SVD\nfrom surprise import SVDpp\nfrom surprise import NMF\nfrom surprise.model_selection import train_test_split\nfrom surprise.model_selection import GridSearchCV\nimport heapq\n\n# Packages for model evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom time import time\n\n# Package to suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Packages for saving models\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:22.432096Z","iopub.execute_input":"2021-07-15T18:12:22.432498Z","iopub.status.idle":"2021-07-15T18:12:23.689552Z","shell.execute_reply.started":"2021-07-15T18:12:22.432463Z","shell.execute_reply":"2021-07-15T18:12:23.688638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading in data","metadata":{}},{"cell_type":"code","source":"df_sample_submission = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/sample_submission.csv')\ndf_movies = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/movies.csv')\ndf_imdb = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/imdb_data.csv')\ndf_genome_scores = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_scores.csv')\ndf_genome_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/genome_tags.csv')\ndf_train = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/train.csv')\ndf_test = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/test.csv')\ndf_tags = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/tags.csv')\ndf_links = pd.read_csv('/kaggle/input/edsa-movie-recommendation-challenge/links.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:23.690838Z","iopub.execute_input":"2021-07-15T18:12:23.691277Z","iopub.status.idle":"2021-07-15T18:12:49.516495Z","shell.execute_reply.started":"2021-07-15T18:12:23.691246Z","shell.execute_reply":"2021-07-15T18:12:49.51515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Overview¶\nLet's first look at the shape (number of entries/rows and columns) of the datasets in order to have a general overview.","metadata":{}},{"cell_type":"code","source":"# Declaring a list that contains the names of the dataframes\ndfs = [df_train, df_test, df_genome_scores, df_genome_tags, df_imdb, df_links, df_movies, df_tags]\n# Create a list of the names of the imported datasets\ndf_names = ['train', 'test', 'genome_scores', 'genome_tags',\n            'imdb_data', 'links', 'movies', 'tags']\ndfs_dict = {}  # declaring an empty dictionary\nfor name, data in zip(df_names, dfs):  # iterate over the list and dictionary\n    dfs_dict[name] = [data.shape[0], data.shape[1]]\n    df_prop = pd.DataFrame(dfs_dict,\n                          index=['rows', 'columns']).transpose()\ndf_properties = df_prop.sort_values(by='rows', ascending=False)\n\ndf_properties  # view the final output","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.518247Z","iopub.execute_input":"2021-07-15T18:12:49.518595Z","iopub.status.idle":"2021-07-15T18:12:49.564445Z","shell.execute_reply.started":"2021-07-15T18:12:49.518562Z","shell.execute_reply":"2021-07-15T18:12:49.563295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.566136Z","iopub.execute_input":"2021-07-15T18:12:49.566494Z","iopub.status.idle":"2021-07-15T18:12:49.578071Z","shell.execute_reply.started":"2021-07-15T18:12:49.56646Z","shell.execute_reply":"2021-07-15T18:12:49.577281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.579419Z","iopub.execute_input":"2021-07-15T18:12:49.579793Z","iopub.status.idle":"2021-07-15T18:12:49.602228Z","shell.execute_reply.started":"2021-07-15T18:12:49.579753Z","shell.execute_reply":"2021-07-15T18:12:49.601356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imdb.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.603818Z","iopub.execute_input":"2021-07-15T18:12:49.604159Z","iopub.status.idle":"2021-07-15T18:12:49.628299Z","shell.execute_reply.started":"2021-07-15T18:12:49.604126Z","shell.execute_reply":"2021-07-15T18:12:49.627148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genome_scores.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.63067Z","iopub.execute_input":"2021-07-15T18:12:49.631023Z","iopub.status.idle":"2021-07-15T18:12:49.647673Z","shell.execute_reply.started":"2021-07-15T18:12:49.63099Z","shell.execute_reply":"2021-07-15T18:12:49.646715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genome_tags.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.649357Z","iopub.execute_input":"2021-07-15T18:12:49.649851Z","iopub.status.idle":"2021-07-15T18:12:49.668197Z","shell.execute_reply.started":"2021-07-15T18:12:49.6498Z","shell.execute_reply":"2021-07-15T18:12:49.666826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.669736Z","iopub.execute_input":"2021-07-15T18:12:49.670087Z","iopub.status.idle":"2021-07-15T18:12:49.689448Z","shell.execute_reply.started":"2021-07-15T18:12:49.670055Z","shell.execute_reply":"2021-07-15T18:12:49.688352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.691134Z","iopub.execute_input":"2021-07-15T18:12:49.691551Z","iopub.status.idle":"2021-07-15T18:12:49.70684Z","shell.execute_reply.started":"2021-07-15T18:12:49.691511Z","shell.execute_reply":"2021-07-15T18:12:49.70567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tags.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.708604Z","iopub.execute_input":"2021-07-15T18:12:49.708994Z","iopub.status.idle":"2021-07-15T18:12:49.728424Z","shell.execute_reply.started":"2021-07-15T18:12:49.708958Z","shell.execute_reply":"2021-07-15T18:12:49.727318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_links.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.729893Z","iopub.execute_input":"2021-07-15T18:12:49.730266Z","iopub.status.idle":"2021-07-15T18:12:49.749035Z","shell.execute_reply.started":"2021-07-15T18:12:49.730234Z","shell.execute_reply":"2021-07-15T18:12:49.748081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysis of imdb_data\nThe plot below is a visual representation of the different columns in the imdb_data dataset with their percentage of missing values.\n\nThere is a high number of movies without budget, director or title cast. Such high proportions of missing data largely disqualifies this particular set from our current modelling task.","metadata":{}},{"cell_type":"code","source":"# The percentage of each column of missing values\ntotal = df_imdb.isnull().sum().sort_values(ascending=False)\npercent_1 = df_imdb.isnull().sum()/df_imdb.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2],\n                         axis=1, keys=['Total', '(%) missing'])\nmissing_data['(%) missing'].plot(kind='barh')\nplt.xlabel('(%) Missing Values')\nplt.ylabel('Columns with Missing Values')\nplt.title('Percentage of Missing Values per Column')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:49.750466Z","iopub.execute_input":"2021-07-15T18:12:49.751009Z","iopub.status.idle":"2021-07-15T18:12:50.063708Z","shell.execute_reply.started":"2021-07-15T18:12:49.750972Z","shell.execute_reply":"2021-07-15T18:12:50.062557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Duplicates","metadata":{}},{"cell_type":"code","source":"# Checking for unique users and movieId's in the train dataset\nusers = len(df_train.userId.unique())\nitems = len(df_train.movieId.unique())\nprint('There are {} unique users and {}\\\n unique movies train dataset with {} duplicated entries'.format(users, items, df_train[df_train.duplicated()].count().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:50.065105Z","iopub.execute_input":"2021-07-15T18:12:50.065451Z","iopub.status.idle":"2021-07-15T18:12:56.466859Z","shell.execute_reply.started":"2021-07-15T18:12:50.065419Z","shell.execute_reply":"2021-07-15T18:12:56.465733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Merging of Datasets\nNow that we have a basic understanding of the data we are working with, we merge the sets below for more in depth analysis in the EDA section.","metadata":{}},{"cell_type":"code","source":"# Combining both train and movies datasets by using movieId\n# as the matching column between both datasets\ntrain_movies_df = pd.merge(df_train,\n                           df_movies,\n                           how='left',\n                           on='movieId')\n\n# Combining all the observations in movies_metadata_df with imdb_data\n# using movieId as the matching column between both dataframes\nmovies_metadata_df = pd.merge(train_movies_df,\n                              df_imdb,\n                              how='left',\n                              on='movieId')\n\nmovies_metadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:12:56.468311Z","iopub.execute_input":"2021-07-15T18:12:56.468617Z","iopub.status.idle":"2021-07-15T18:13:03.692453Z","shell.execute_reply.started":"2021-07-15T18:12:56.468586Z","shell.execute_reply":"2021-07-15T18:13:03.691301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_ranking = movies_metadata_df[['title','rating']].groupby('title').mean().sort_values('rating', ascending=False)\nmovies_ranking.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:13:03.693784Z","iopub.execute_input":"2021-07-15T18:13:03.694094Z","iopub.status.idle":"2021-07-15T18:13:08.555609Z","shell.execute_reply.started":"2021-07-15T18:13:03.694064Z","shell.execute_reply":"2021-07-15T18:13:08.554585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA\nDiscovery phase and data understanding","metadata":{}},{"cell_type":"code","source":"#dropping the timestamp column because we don't need it\ndf_train = df_train.drop('timestamp', axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movie_ratings = pd.merge(df_movies, df_train)\nmovie_ratings.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive Statistics\nThe descriptive statistics of the movies dataset below does not provide any useful information","metadata":{}},{"cell_type":"code","source":"\ndf_movies.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Visualizations\nDistribution of rating score in ratings df\nShowing the distribution of ratings given in the ratings dataset. In the plot below, we see that the rating scale ranges from 0.5 to 5.0 with increments of 0.5. The most prevalent ratings given are 3.0, and 4.0 with 5.0 coming in third. We also see that people were less likely to give low ratings as evidenced by the low number of movies rated between 0.5 and 2.5.","metadata":{}},{"cell_type":"code","source":"\nfig, ax = plt.subplots(figsize = (14,8))\nsns.countplot(x = df_train.rating)\nplt.suptitle('Frequency Distribution of Rating Scores', fontsize = 20);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of User Ratings","metadata":{}},{"cell_type":"code","source":"print (f'Average rating in the dataset: {np.mean(df_train[\"rating\"])}')\n\nwith sns.axes_style('white'):\n    g = sns.factorplot(\"rating\", data=df_train, aspect=2.5, kind='count')\n    g.set_ylabels(\"Total number of ratings\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Average Rating per Genre\nThe genres with the highest average ratings are Film-Noir, War and Documentary genres","metadata":{}},{"cell_type":"code","source":"#subsetting the genres and rating columns from movie_ratings\ngenre_ratingdf = movie_ratings.loc[:,['genres', 'rating']]\n\n# Unravel the genre columns\ngenre_ratingdf = genre_ratingdf.set_index(genre_ratingdf.columns.drop('genres',1).tolist()).genres.str.split('|', expand=True).stack().reset_index().rename(columns={0:'genres'}).loc[:, genre_ratingdf.columns]\n\n# group by genres and their mean rating score and resetting the index\ngenre_mean_rating = pd.DataFrame(genre_ratingdf.groupby('genres')['rating'].mean()).reset_index()\n\n# plotting the figure\nfig, ax = plt.subplots(figsize=(14, 8))\nsns.barplot(x = 'genres', y = 'rating', data = genre_mean_rating)\n\nax.tick_params(axis='x', labelsize= 15, rotation=90)\nax.set_xlabel('Genres', fontsize= 20)\nax.set_ylabel('Average Rating Score',fontsize= 20)\nplt.suptitle('Average Rating per Genre', fontsize= 25);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Observation\n\nThe bar graph above shows that most movies have a rating of 4 followed by 3 while the least rated movies were rated 0.5 and 1.5. The mean rating is around 3.5 revealing that users tend to give higher ratings to movies in general.","metadata":{}},{"cell_type":"code","source":"movies_ranking['No_of_ratings'] = movies_metadata_df.groupby('title')['rating'].count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"movies_ranking.sort_values(by=['No_of_ratings', 'rating'],\n                          ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set plot size\nsns.set(rc={'figure.figsize':(12,9)})\n\n# Plot Number of rating for every rating category.\nsns.scatterplot(x='rating', y='No_of_ratings', data=movies_ranking)\nplt.title('Number of ratings per average rating per movie')\nplt.xlabel('Rating')\nplt.ylabel('Number of ratings')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above scatterplot shows that there is a strong correlation between the number of ratings a rating-category contains and the rating category, i.e. movies that have more ratings (views) strongly tend to also have higher average ratings. This supports the previously established notion that users tend to give higher ratings in general. The plot below similarly shows that even movies with more than one hundred views (ratings) the average rating stays consistent around 3.5.","metadata":{}},{"cell_type":"code","source":"# Average rating of movies in the dataset\navg_rating = df_train.groupby('movieId')['rating'].mean()\n\n# Plotting the results\nplt.figure(figsize=(12,10))\navg_rating.plot(kind='hist')\nplt.ylabel('Frequency')\nplt.xlabel('Movie Rating')\nplt.title('Average ratings of movies with 100 or more viewers')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below we look at average rating for individual movie directors. From the resulting dataframe it is clear that certian directors like Quentin Tarantino, Lilly Wachowski, and Stephen Kind have both higher-than-average average ratings AND higher numbers of ratings (views).","metadata":{}},{"cell_type":"code","source":"best_director = pd.DataFrame(movies_metadata_df.groupby('director')['rating'].mean().\n                             sort_values(ascending=False))\nbest_director['No_of_ratings'] = movies_metadata_df.groupby('director')['rating'].count()\nbest_director.sort_values(by=['No_of_ratings', 'rating'], ascending=False).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plot below shows the distribution of ratings for directors, extending the positive correclation between 'number of ratings' and 'rating' to 'directors' as well.","metadata":{}},{"cell_type":"code","source":"# Set plot size\nsns.set(rc={'figure.figsize':(12,9)})\n\nsns.scatterplot(x = 'rating', y = 'No_of_ratings', data = best_director).set_title('Number of ratings per average rating per director')\nplt.xlabel('Ratings')\nplt.ylabel('Number of Ratings')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Most common Genres**","metadata":{}},{"cell_type":"code","source":"# Create dataframe containing only the movieId and genres\nmovies_genres = pd.DataFrame(df_movies[['movieId', 'genres']],\n                             columns=['movieId', 'genres'])\n\n# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\nmovies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n\n# Create expanded dataframe where each movie-genre combination is in a seperate row\nmovies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n                             columns=['movieId', 'genres'])\n\nmovies_genres.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the genres from most common to least common\nplot = plt.figure(figsize=(15, 10))\nplt.title('Most common genres\\n', fontsize=20)\nsns.countplot(y=\"genres\", data=movies_genres,\n              order=movies_genres['genres'].value_counts(ascending=False).index,\n              palette='Reds_r')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Prepartion","metadata":{}},{"cell_type":"code","source":"# Creating a small test dataframe to evaluate our models\ntests = df_train.copy()\n\ntests = tests.head(20000)\n\n# Creating the training data\nreader = Reader(rating_scale=(0.5, 5))\ntest_data = Dataset.load_from_df(tests[['userId','movieId','rating']], reader)\n\n# Compute similarities between users using cosine distance\nsim_options = {\"name\": \"cosine\",\n               \"user_based\": True}  \n\n# Evaluate the model \nuser = KNNWithMeans(sim_options=sim_options)\ncv = cross_validate(user, test_data, cv=5, measures=['RMSE'], verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:13:08.556853Z","iopub.execute_input":"2021-07-15T18:13:08.557159Z","iopub.status.idle":"2021-07-15T18:14:04.164558Z","shell.execute_reply.started":"2021-07-15T18:13:08.55713Z","shell.execute_reply":"2021-07-15T18:14:04.163485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute similarities between items using cosine distance\nsim_options = {\"name\": \"cosine\",\n               \"user_based\": False}  \n\n# Fit the KNNwithmeans algorithm to the training set\nitem_based = KNNWithMeans(sim_options=sim_options)\n\n# Evaluate the model \ncv = cross_validate(item_based, test_data, cv=5, measures=['RMSE'], verbose=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:14:04.165967Z","iopub.execute_input":"2021-07-15T18:14:04.166288Z","iopub.status.idle":"2021-07-15T18:14:10.410334Z","shell.execute_reply.started":"2021-07-15T18:14:04.166254Z","shell.execute_reply":"2021-07-15T18:14:10.409282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling phase\n\nHere you can apply the models outline in the Intro to Recommender Notebook. You only need to apply one version \nbe it Content based or Collabrative method\n\n","metadata":{}},{"cell_type":"code","source":"# Loading as Surprise dataframe \nreader = Reader()\ndata = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], reader)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:14:10.413828Z","iopub.execute_input":"2021-07-15T18:14:10.414201Z","iopub.status.idle":"2021-07-15T18:14:24.883376Z","shell.execute_reply.started":"2021-07-15T18:14:10.414152Z","shell.execute_reply":"2021-07-15T18:14:24.882179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data split 85/15\ntrainset, testset = train_test_split(data, test_size=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:14:24.888022Z","iopub.execute_input":"2021-07-15T18:14:24.888545Z","iopub.status.idle":"2021-07-15T18:15:11.006345Z","shell.execute_reply.started":"2021-07-15T18:14:24.888493Z","shell.execute_reply":"2021-07-15T18:15:11.00507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"co_clust = CoClustering()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:15:11.007676Z","iopub.execute_input":"2021-07-15T18:15:11.007982Z","iopub.status.idle":"2021-07-15T18:15:11.011798Z","shell.execute_reply.started":"2021-07-15T18:15:11.007944Z","shell.execute_reply":"2021-07-15T18:15:11.01083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting our trainset\nco_clust.fit(trainset)\n\n# Using the 15% testset to make predictions\npredictions = co_clust.test(testset) \npredictions\n\ntest = pd.DataFrame(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:15:11.013078Z","iopub.execute_input":"2021-07-15T18:15:11.013382Z","iopub.status.idle":"2021-07-15T18:26:29.946191Z","shell.execute_reply.started":"2021-07-15T18:15:11.013354Z","shell.execute_reply":"2021-07-15T18:26:29.945001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View the head\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:26:29.947889Z","iopub.execute_input":"2021-07-15T18:26:29.948249Z","iopub.status.idle":"2021-07-15T18:26:29.967327Z","shell.execute_reply.started":"2021-07-15T18:26:29.948211Z","shell.execute_reply":"2021-07-15T18:26:29.966062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We are trying to predict ratings for every userId / movieId pair, we implement the below list comprehension to achieve this.\nratings_predictions=[co_clust.predict(row.userId, row.movieId) for _,row in df_test.iterrows()]\nratings_predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:27:09.215315Z","iopub.execute_input":"2021-07-15T18:27:09.215873Z","iopub.status.idle":"2021-07-15T18:36:04.542906Z","shell.execute_reply.started":"2021-07-15T18:27:09.21584Z","shell.execute_reply":"2021-07-15T18:36:04.542116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Converting our prediction into a familiar format-Dataframe\ndf_pred=pd.DataFrame(ratings_predictions)\ndf_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:36:04.544304Z","iopub.execute_input":"2021-07-15T18:36:04.54476Z","iopub.status.idle":"2021-07-15T18:36:13.595001Z","shell.execute_reply.started":"2021-07-15T18:36:04.544728Z","shell.execute_reply":"2021-07-15T18:36:13.59388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Renaming our predictions to original names\ndf_pred=df_pred.rename(columns={'uid':'userId', 'iid':'movieId','est':'rating'})\ndf_pred.drop(['r_ui','details'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:36:13.596734Z","iopub.execute_input":"2021-07-15T18:36:13.597055Z","iopub.status.idle":"2021-07-15T18:36:13.918585Z","shell.execute_reply.started":"2021-07-15T18:36:13.597025Z","shell.execute_reply":"2021-07-15T18:36:13.917497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Snippet of our ratings\ndf_pred.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T18:36:13.920251Z","iopub.execute_input":"2021-07-15T18:36:13.920539Z","iopub.status.idle":"2021-07-15T18:36:13.932158Z","shell.execute_reply.started":"2021-07-15T18:36:13.920511Z","shell.execute_reply":"2021-07-15T18:36:13.931206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the prediction dataset\ndf_pred.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Submission File\nWe make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n\nWe will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file.","metadata":{"_kg_hide-output":true}},{"cell_type":"code","source":"# Submission final csv. file\ndf_pred.to_csv(\"coClustering.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Make Submission\nHit the blue Publish button at the top of your notebook screen. It will take some time for your kernel to run. When it has finished your navigation bar at the top of the screen will have a tab for Output. This only shows up if you have written an output file (like we did in the Prepare Submission File step).","metadata":{}},{"cell_type":"markdown","source":"Example below of how the output would look once published","metadata":{}},{"cell_type":"code","source":"# initialize list of lists\ndata = [['tom', 10], ['nick', 15], ['juli', 14]]\n  \n# Create the pandas DataFrame\ndf = pd.DataFrame(data, columns = ['Name', 'Age'])\n  \n# print dataframe.\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('my_test_output.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Collaborators\n1. Kwanda Silekwa\n2. Nomfundo Manyisa\n3. Sihle Riti\n4. Thanyani Khedzi\n5. Thembinkosi Malefo\n6. Ofentse Makeketlane","metadata":{}},{"cell_type":"markdown","source":"# Reference","metadata":{}},{"cell_type":"markdown","source":"https://towardsdatascience.com/exploring-movie-data-with-interactive-visualizations-c22e8ce5f663","metadata":{}},{"cell_type":"markdown","source":"https://in.springboard.com/blog/recommender-system-with-python/","metadata":{}},{"cell_type":"markdown","source":"https://asdkazmi.medium.com/ai-movies-recommendation-system-with-clustering-based-k-means-algorithm-f04467e02fcd","metadata":{}},{"cell_type":"markdown","source":"https://github.com/Wonuabimbola/movie-recommendation-system/blob/master/movie_rec_system.ipynb","metadata":{}},{"cell_type":"markdown","source":"https://towardsdatascience.com/unsupervised-classification-project-building-a-movie-recommender-with-clustering-analysis-and-4bab0738efe6","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dibyawantrivedi/movie-recommendation-system","metadata":{}},{"cell_type":"markdown","source":"https://towardsdatascience.com/how-to-build-a-simple-recommender-system-in-python-375093c3fb7d","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}